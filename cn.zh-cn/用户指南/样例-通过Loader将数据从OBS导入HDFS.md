# 样例：通过Loader将数据从OBS导入HDFS<a name="ZH-CN_TOPIC_0173177975"></a>

## 操作场景<a name="scb2c24634b0344dba198e390d6cea59e"></a>

用户需要将大量数据从集群外导入集群内的时候，可以选择从OBS导入到HDFS的方式。

## 前提条件<a name="sb8fe6f0415124936bb9a7810db345b17"></a>

-   已准备业务数据。
-   已创建分析集群。

## 操作步骤<a name="s12aa651484ea43cd846dd6d94301117b"></a>

1.  将业务数据上传到用户的OBS桶。
2.  获取用户的AK/SK信息，然后创建一个OBS连接和一个HDFS连接。

    具体可参见[Loader连接配置说明](Loader连接配置说明.md)。

3.  访问Loader页面。具体可参见[Loader页面介绍](Loader使用简介.md#s12f4baccf3914471bee631d0ca198278)。

    如果是启用了Kerberos认证的分析集群，可参见[访问Hue的WebUI](访问Hue的WebUI.md)。

4.  单击“新建作业“。
5.  在“基本信息“填写参数。
    1.  在“名称“填写一个作业的名称。例如“obs2hdfs“。
    2.  在“源连接“选择已创建的OBS连接。
    3.  “目的连接“选择已创建的HDFS连接。

6.  在“自“填写源连接参数。

    1.  在“桶名“填写业务数据所保存的桶名称。
    2.  在“源目录或文件“填写业务数据在桶的具体位置。

        如果是单个文件，需要填写包含文件名的完整路径。如果是目录，填写目录的完整路径

    3.  <a name="ld408930f2f5d426289bd0acd45f8e485"></a>“文件格式“填写业务数据文件的类型。

    可参见[表1](Loader作业源连接配置说明.md#t965be05e8bc445ceb862e8444f43702d)。

7.  在“至“填写目的连接参数。

    1.  在“定入目录“填写业务数据在HDFS要保存的目录名称。

        如果是启用Kerberos认证的集群，当前访问Loader的用户对保存数据的目录需要有写入权限。

    2.  在“文件格式“填写业务数据文件的类型。

        需要与[6.c](#ld408930f2f5d426289bd0acd45f8e485)的类型对应。

    3.  在“压缩格式“填写一种压缩的算法。例如选择不压缩“NONE“。
    4.  在“是否覆盖“选择已有文件的处理方式，选择“True“。
    5.  单击“显示高级属性“，在“换行符“填写业务数据保存时，系统填充的换行字符。
    6.  在“字段分割符“填写业务数据保存时，系统填充的分割字符。

    可参见[表5](Loader作业目的连接配置说明.md#t0549e6c84ff84d08a87e8e1856d0561b)。

8.  在“任务配置“填写作业的运行参数。
    1.  在“抽取并发数“填写map任务的个数。
    2.  在“加载\(写入\)并发数“填写reduce任务的个数。

        目的连接为HDFS连接时，不显示“加载\(写入\)并发数“参数。

    3.  “单个分片的最大错误记录数“填写错误记录阈值。
    4.  在“脏数据目录“填写一个脏数据的保存位置，例如“/user/sqoop/obs2hdfs-dd“。

9.  单击“保存并运行“。

    在“管理作业界面“，查看作业运行结果。可以单击“刷新列表“获取作业的最新状态。


