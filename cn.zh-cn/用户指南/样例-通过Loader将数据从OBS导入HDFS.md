# 样例：通过Loader将数据从OBS导入HDFS<a name="ZH-CN_TOPIC_0071958198"></a>

## 操作场景<a name="zh-cn_topic_0071084995_section13507962172159"></a>

用户需要将大量数据从集群外导入集群内的时候，可以选择从OBS导入到HDFS的方式。

## 前提条件<a name="zh-cn_topic_0071084995_section23899914172238"></a>

-   已准备业务数据。
-   已创建分析集群。

## 操作步骤<a name="zh-cn_topic_0071084995_section13552161172344"></a>

1.  将业务数据上传到用户的OBS桶。
2.  获取用户的AK/SK信息，然后创建一个OBS连接和一个HDFS连接。

    具体可参见[Loader连接配置说明](Loader连接配置说明.md#ZH-CN_TOPIC_0071958193)。

3.  访问Loader页面。具体可参见[Loader页面介绍](Loader使用简介.md#zh-cn_topic_0070859522_section27711559)。

    如果是启用了Kerberos认证的分析集群，可参见[访问Hue的WebUI](访问Hue的WebUI.md)。

4.  单击“新建作业“。
5.  在“基本信息“填写参数。
    1.  在“名称“填写一个作业的名称。例如“obs2hdfs“。
    2.  在“源连接“选择已创建的OBS连接。
    3.  “目的连接“选择已创建的HDFS连接。

6.  在“自“填写源连接参数。

    1.  在“桶名“填写业务数据所保存的桶名称。
    2.  在“源目录或文件“填写业务数据在桶的具体位置。

        如果是单个文件，需要填写包含文件名的完整路径。如果是目录，填写目录的完整路径

    3.  <a name="zh-cn_topic_0071084995_li1460201102036"></a>“文件格式“填写业务数据文件的类型。

    可参见[表1](Loader作业源连接配置说明.md#zh-cn_topic_0071084972_table47534913165858)。

7.  在“至“填写目的连接参数。

    1.  在“定入目录“填写业务数据在HDFS要保存的目录名称。

        如果是启用Kerberos认证的集群，当前访问Loader的用户对保存数据的目录需要有写入权限。

    2.  在“文件格式“填写业务数据文件的类型。

        需要与[6.c](#zh-cn_topic_0071084995_li1460201102036)的类型对应。

    3.  在“压缩格式“填写一种压缩的算法。例如选择不压缩“NONE“。
    4.  在“是否覆盖“选择已有文件的处理方式，选择“True“。
    5.  单击“显示高级属性“，在“换行符“填写业务数据保存时，系统填充的换行字符。
    6.  在“字段分割符“填写业务数据保存时，系统填充的分割字符。

    可参见[表5](Loader作业目的连接配置说明.md#zh-cn_topic_0071084973_table25755291172642)。

8.  在“任务配置“填写作业的运行参数。
    1.  在“抽取并发数“填写map任务的个数。
    2.  在“加载\(写入\)并发数“填写reduce任务的个数。

        目的连接为HDFS连接时，不显示“加载\(写入\)并发数“参数。

    3.  “单个分片的最大错误记录数“填写错误记录阈值。
    4.  在“脏数据目录“填写一个脏数据的保存位置，例如“/user/sqoop/obs2hdfs-dd“。

9.  单击“保存并运行“。

    在“管理作业界面“，查看作业运行结果。可以单击“刷新列表“获取作业的最新状态。


